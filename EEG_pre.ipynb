{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c080fb73-80a2-46ce-be7d-9156929c8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.signal\n",
    "\n",
    "def matrix_from_csv_file(file_path):\n",
    "\t\n",
    "\tcsv_data = np.genfromtxt(file_path, delimiter = ',')\n",
    "\tfull_matrix = csv_data[1:]\n",
    "\t#headers = csv_data[0] # Commented since not used or returned [fcampelo]\n",
    "\t\n",
    "\treturn full_matrix\n",
    "\n",
    "\n",
    "def get_time_slice(full_matrix, start = 0., period = 1.):\n",
    "\n",
    "\t\n",
    "\t# Changed for greater efficiency [fcampelo]\n",
    "\trstart  = full_matrix[0, 0] + start\n",
    "\tindex_0 = np.max(np.where(full_matrix[:, 0] <= rstart))\n",
    "\tindex_1 = np.max(np.where(full_matrix[:, 0] <= rstart + period))\n",
    "\t\n",
    "\tduration = full_matrix[index_1, 0] - full_matrix[index_0, 0]\n",
    "\treturn full_matrix[index_0:index_1, :], duration\n",
    "\n",
    "\n",
    "def feature_mean(matrix):\n",
    "\n",
    "\t\n",
    "\tret = np.mean(matrix, axis = 0).flatten()\n",
    "\tnames = ['mean_' + str(i) for i in range(matrix.shape[1])]\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "\n",
    "def feature_mean_d(h1, h2):\n",
    "\n",
    "\tret = (feature_mean(h2)[0] - feature_mean(h1)[0]).flatten()\n",
    "\t\n",
    "\t\n",
    "\t# Fixed naming [fcampelo]\n",
    "\tnames = ['mean_d_h2h1_' + str(i) for i in range(h1.shape[1])]\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "\n",
    "def feature_mean_q(q1, q2, q3, q4):\n",
    "\n",
    "\tv1 = feature_mean(q1)[0]\n",
    "\tv2 = feature_mean(q2)[0]\n",
    "\tv3 = feature_mean(q3)[0]\n",
    "\tv4 = feature_mean(q4)[0]\n",
    "\tret = np.hstack([v1, v2, v3, v4, \n",
    "\t\t\t\t     v1 - v2, v1 - v3, v1 - v4, \n",
    "\t\t\t\t\t v2 - v3, v2 - v4, v3 - v4]).flatten()\n",
    "\t\n",
    "\t\n",
    "\t# Fixed naming [fcampelo]\n",
    "\tnames = []\n",
    "\tfor i in range(4): # for all quarter-windows\n",
    "\t\tnames.extend(['mean_q' + str(i + 1) + \"_\" + str(j) for j in range(len(v1))])\n",
    "\t\n",
    "\tfor i in range(3): # for quarter-windows 1-3\n",
    "\t\tfor j in range((i + 1), 4): # and quarter-windows (i+1)-4\n",
    "\t\t\tnames.extend(['mean_d_q' + str(i + 1) + 'q' + str(j + 1) + \"_\" + str(k) for k in range(len(v1))])\n",
    "\t\t\t \n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_stddev(matrix):\n",
    "\n",
    "\t\n",
    "\t# fix ddof for finite sampling correction (N-1 instead of N in denominator)\n",
    "\tret = np.std(matrix, axis = 0, ddof = 1).flatten()\n",
    "\tnames = ['std_' + str(i) for i in range(matrix.shape[1])]\n",
    "\t\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "\n",
    "def feature_stddev_d(h1, h2):\n",
    "\n",
    "\t\n",
    "\tret = (feature_stddev(h2)[0] - feature_stddev(h1)[0]).flatten()\n",
    "\t\n",
    "\t# Fixed naming [fcampelo]\n",
    "\tnames = ['std_d_h2h1_' + str(i) for i in range(h1.shape[1])]\n",
    "\t\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_moments(matrix):\n",
    "\n",
    "\n",
    "\tskw = scipy.stats.skew(matrix, axis = 0, bias = False)\n",
    "\tkrt = scipy.stats.kurtosis(matrix, axis = 0, bias = False)\n",
    "\tret  = np.append(skw, krt)\n",
    "\t\t\n",
    "\tnames = ['skew_' + str(i) for i in range(matrix.shape[1])]\n",
    "\tnames.extend(['kurt_' + str(i) for i in range(matrix.shape[1])])\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def feature_max(matrix):\n",
    "\n",
    "\t\n",
    "\tret = np.max(matrix, axis = 0).flatten()\n",
    "\tnames = ['max_' + str(i) for i in range(matrix.shape[1])]\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "\n",
    "def feature_max_d(h1, h2):\n",
    "\n",
    "\t\n",
    "\tret = (feature_max(h2)[0] - feature_max(h1)[0]).flatten()\n",
    "\t\n",
    "\t# Fixed naming [fcampelo]\n",
    "\tnames = ['max_d_h2h1_' + str(i) for i in range(h1.shape[1])]\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "def feature_max_q(q1, q2, q3, q4):\n",
    "\n",
    "\tv1 = feature_max(q1)[0]\n",
    "\tv2 = feature_max(q2)[0]\n",
    "\tv3 = feature_max(q3)[0]\n",
    "\tv4 = feature_max(q4)[0]\n",
    "\tret = np.hstack([v1, v2, v3, v4, \n",
    "\t\t\t\t     v1 - v2, v1 - v3, v1 - v4, \n",
    "\t\t\t\t\t v2 - v3, v2 - v4, v3 - v4]).flatten()\n",
    "\t\n",
    "\t\n",
    "\t# Fixed naming [fcampelo]\n",
    "\tnames = []\n",
    "\tfor i in range(4): # for all quarter-windows\n",
    "\t\tnames.extend(['max_q' + str(i + 1) + \"_\" + str(j) for j in range(len(v1))])\n",
    "\t\n",
    "\tfor i in range(3): # for quarter-windows 1-3\n",
    "\t\tfor j in range((i + 1), 4): # and quarter-windows (i+1)-4\n",
    "\t\t\tnames.extend(['max_d_q' + str(i + 1) + 'q' + str(j + 1) + \"_\" + str(k) for k in range(len(v1))])\n",
    "\t\t\t \n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "def feature_min(matrix):\n",
    "\n",
    "\t\n",
    "\tret = np.min(matrix, axis = 0).flatten()\n",
    "\tnames = ['min_' + str(i) for i in range(matrix.shape[1])]\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "\n",
    "def feature_min_d(h1, h2):\n",
    "\n",
    "\t\n",
    "\tret = (feature_min(h2)[0] - feature_min(h1)[0]).flatten()\n",
    "\t\n",
    "\t# Fixed naming [fcampelo]\n",
    "\tnames = ['min_d_h2h1_' + str(i) for i in range(h1.shape[1])]\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "def feature_min_q(q1, q2, q3, q4):\n",
    "\n",
    "\tv1 = feature_min(q1)[0]\n",
    "\tv2 = feature_min(q2)[0]\n",
    "\tv3 = feature_min(q3)[0]\n",
    "\tv4 = feature_min(q4)[0]\n",
    "\tret = np.hstack([v1, v2, v3, v4, \n",
    "\t\t\t\t     v1 - v2, v1 - v3, v1 - v4, \n",
    "\t\t\t\t\t v2 - v3, v2 - v4, v3 - v4]).flatten()\n",
    "\t\n",
    "\t\n",
    "\t# Fixed naming [fcampelo]\n",
    "\tnames = []\n",
    "\tfor i in range(4): # for all quarter-windows\n",
    "\t\tnames.extend(['min_q' + str(i + 1) + \"_\" + str(j) for j in range(len(v1))])\n",
    "\t\n",
    "\tfor i in range(3): # for quarter-windows 1-3\n",
    "\t\tfor j in range((i + 1), 4): # and quarter-windows (i+1)-4\n",
    "\t\t\tnames.extend(['min_d_q' + str(i + 1) + 'q' + str(j + 1) + \"_\" + str(k) for k in range(len(v1))])\n",
    "\t\t\t \n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "def feature_covariance_matrix(matrix):\n",
    "\n",
    "    \n",
    "\tcovM = np.cov(matrix.T)\n",
    "\tindx = np.triu_indices(covM.shape[0])\n",
    "\tret  = covM[indx]\n",
    "\t\n",
    "\tnames = []\n",
    "\tfor i in np.arange(0, covM.shape[1]):\n",
    "\t\tfor j in np.arange(i, covM.shape[1]):\n",
    "\t\t\tnames.extend(['covM_' + str(i) + '_' + str(j)])\n",
    "\t\n",
    "\treturn ret, names, covM\n",
    "\n",
    "\n",
    "def feature_eigenvalues(covM):\n",
    "\n",
    "\t\n",
    "\tret   = np.linalg.eigvals(covM).flatten()\n",
    "\tnames = ['eigenval_' + str(i) for i in range(covM.shape[0])]\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "def feature_logcov(covM):\n",
    "\n",
    "\tlog_cov = scipy.linalg.logm(covM)\n",
    "\tindx = np.triu_indices(log_cov.shape[0])\n",
    "\tret  = np.abs(log_cov[indx])\n",
    "\t\n",
    "\tnames = []\n",
    "\tfor i in np.arange(0, log_cov.shape[1]):\n",
    "\t\tfor j in np.arange(i, log_cov.shape[1]):\n",
    "\t\t\tnames.extend(['logcovM_' + str(i) + '_' + str(j)])\n",
    "\t\n",
    "\treturn ret, names, log_cov\n",
    "\n",
    "\n",
    "\n",
    "def feature_fft(matrix, period = 1., mains_f = 50., \n",
    "\t\t\t\tfilter_mains = True, filter_DC = True,\n",
    "\t\t\t\tnormalise_signals = True,\n",
    "\t\t\t\tntop = 10, get_power_spectrum = True):      #make ntop  as 10\n",
    "\n",
    "\t\n",
    "\t# Signal properties\n",
    "\tN   = matrix.shape[0] # number of samples\n",
    "\tT = period / N        # Sampling period\n",
    "\t\n",
    "\t# Scale all signals to interval [-1, 1] (if requested)\n",
    "\tif normalise_signals:\n",
    "\t\tmatrix = -1 + 2 * (matrix - np.min(matrix)) / (np.max(matrix) - np.min(matrix))\n",
    "\t\n",
    "\t# Compute the (absolute values of the) FFT\n",
    "\t# Extract only the first half of each FFT vector, since all the information\n",
    "\t# is contained there (by construction the FFT returns a symmetric vector).\n",
    "\tfft_values = np.abs(scipy.fft.fft(matrix, axis = 0))[0:N//2] * 2 / N\n",
    "\t\n",
    "\t# Compute the corresponding frequencies of the FFT components\n",
    "\tfreqs = np.linspace(0.0, 1.0 / (2.0 * T), N//2)\n",
    "\t\n",
    "\t# Remove DC component (if requested)\n",
    "\tif filter_DC:\n",
    "\t\tfft_values = fft_values[1:]\n",
    "\t\tfreqs = freqs[1:]\n",
    "\t\t\n",
    "\t# Remove mains frequency component(s) (if requested)\n",
    "\tif filter_mains:\n",
    "\t\tindx = np.where(np.abs(freqs - mains_f) <= 1)\n",
    "\t\tfft_values = np.delete(fft_values, indx, axis = 0)\n",
    "\t\tfreqs = np.delete(freqs, indx)\n",
    "\t\n",
    "\t# Extract top N frequencies for each signal\n",
    "\tindx = np.argsort(fft_values, axis = 0)[::-1]\n",
    "\tindx = indx[:ntop]\n",
    "\t\n",
    "\tret = freqs[indx].flatten(order = 'F')\n",
    "\t\n",
    "\t# Make feature names\n",
    "\tnames = []\n",
    "\tfor i in np.arange(fft_values.shape[1]):\n",
    "\t\tnames.extend(['topFreq_' + str(j) + \"_\" + str(i) for j in np.arange(1,11)])\n",
    "\t\n",
    "\tif (get_power_spectrum):\n",
    "\t\tret = np.hstack([ret, fft_values.flatten(order = 'F')])\n",
    "\t\t\n",
    "\t\tfor i in np.arange(fft_values.shape[1]):\n",
    "\t\t\tnames.extend(['fft' + \"{:03d}\".format(int(j)) + \"_\" + str(i) for j in 10 * np.round(freqs, 1)])\n",
    "\t\n",
    "\treturn ret, names\n",
    "\n",
    "\n",
    "def calc_feature_vector(matrix, state):\n",
    "\n",
    "\t\n",
    "\t# Extract the half- and quarter-windows\n",
    "\th1, h2 = np.split(matrix, [ int(matrix.shape[0] / 2) ])\n",
    "\tq1, q2, q3, q4 = np.split(matrix, \n",
    "\t\t\t\t\t\t      [int(0.25 * matrix.shape[0]), \n",
    "\t\t\t\t\t\t\t   int(0.50 * matrix.shape[0]), \n",
    "\t\t\t\t\t\t\t   int(0.75 * matrix.shape[0])])\n",
    "\n",
    "\tvar_names = []\t\n",
    "\t\n",
    "\tx, v = feature_mean(matrix)\n",
    "\tvar_names += v\n",
    "\tvar_values = x\n",
    "\t\n",
    "\tx, v = feature_mean_d(h1, h2)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\n",
    "\tx, v = feature_mean_q(q1, q2, q3, q4)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v = feature_stddev(matrix)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v = feature_stddev_d(h1, h2)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v = feature_moments(matrix)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v = feature_max(matrix)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v = feature_max_d(h1, h2)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\n",
    "\tx, v = feature_max_q(q1, q2, q3, q4)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v = feature_min(matrix)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v = feature_min_d(h1, h2)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\n",
    "\tx, v = feature_min_q(q1, q2, q3, q4)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v, covM = feature_covariance_matrix(matrix)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v = feature_eigenvalues(covM)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v, log_cov = feature_logcov(covM)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tx, v = feature_fft(matrix)\n",
    "\tvar_names += v\n",
    "\tvar_values = np.hstack([var_values, x])\n",
    "\t\n",
    "\tif state != None:\n",
    "\t\tvar_values = np.hstack([var_values, np.array([state])])\n",
    "\t\tvar_names += ['Label']\n",
    "\n",
    "\treturn var_values, var_names\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_feature_vectors_from_samples(file_path, nsamples, period, \n",
    "\t\t\t\t\t\t\t\t\t\t  state = None, \n",
    "\t\t\t\t\t\t\t\t\t\t  remove_redundant = True,\n",
    "\t\t\t\t\t\t\t\t\t\t  cols_to_ignore = None):\n",
    "\n",
    "\t# Read the matrix from file\n",
    "\tmatrix = matrix_from_csv_file(file_path)\n",
    "\t\n",
    "\t# We will start at the very begining of the file\n",
    "\tt = 0.\n",
    "\t\n",
    "\t# No previous vector is available at the start\n",
    "\tprevious_vector = None\n",
    "\t\n",
    "\t# Initialise empty return object\n",
    "\tret = None\n",
    "\t\n",
    "\t# Until an exception is raised or a stop condition is met\n",
    "\twhile True:\n",
    "\t\t# Get the next slice from the file (starting at time 't', with a \n",
    "\t\t# duration of 'period'\n",
    "\t\t# If an exception is raised or the slice is not as long as we expected, \n",
    "\t\t# return the current data available\n",
    "\t\ttry:\n",
    "\t\t\ts, dur = get_time_slice(matrix, start = t, period = period)\n",
    "\t\t\tif cols_to_ignore is not None:\n",
    "\t\t\t\ts = np.delete(s, cols_to_ignore, axis = 1)\n",
    "\t\texcept IndexError:\n",
    "\t\t\tbreak\n",
    "\t\tif len(s) == 0:\n",
    "\t\t\tbreak\n",
    "\t\tif dur < 0.9 * period:\n",
    "\t\t\tbreak\n",
    "\t\t\n",
    "\t\t# Perform the resampling of the vector\n",
    "\t\try, rx = scipy.signal.resample(s[:, 1:], num = nsamples, \n",
    "\t\t\t\t\t\t\t\t t = s[:, 0], axis = 0)\n",
    "\t\t\n",
    "\t\t# Slide the slice by 1/2 period\n",
    "\t\tt += 0.5 * period\n",
    "\t\t\n",
    "\t\t\n",
    "\t\t# Compute the feature vector. We will be appending the features of the \n",
    "\t\t# current time slice and those of the previous one.\n",
    "\t\t# If there was no previous vector we just set it and continue \n",
    "\t\t# with the next vector.\n",
    "\t\tr, headers = calc_feature_vector(ry, state)\n",
    "\t\tif headers is None or len(headers) == 0:\n",
    "\t\t\tprint(\"Headers not initialized. Please check the feature extraction process.\")\n",
    "\t\t\tsys.exit(-1)\n",
    "        \n",
    "\t\tif previous_vector is not None:\n",
    "\t\t\t# If there is a previous vector, the script concatenates the two \n",
    "\t\t\t# vectors and adds the result to the output matrix\n",
    "\t\t\tfeature_vector = np.hstack([previous_vector, r])\n",
    "\t\t\t\n",
    "\t\t\tif ret is None:\n",
    "\t\t\t\tret = feature_vector\n",
    "\t\t\telse:\n",
    "\t\t\t\tret = np.vstack([ret, feature_vector])\n",
    "\t\t\t\t\n",
    "\t\t# Store the vector of the previous window\n",
    "\t\tprevious_vector = r\n",
    "\t\tif state is not None:\n",
    "\t\t\t # Remove the label (last column) of previous vector\n",
    "\t\t\tprevious_vector = previous_vector[:-1] \n",
    "\n",
    "\tfeat_names = [\"lag1_\" + s for s in headers[:-1]] + headers\n",
    "\t\n",
    "\tif remove_redundant:\n",
    "\t\t# Remove redundant lag window features\n",
    "\t\tto_rm = [\"lag1_mean_q3_\", \"lag1_mean_q4_\", \"lag1_mean_d_q3q4_\",\n",
    "\t\t         \"lag1_max_q3_\", \"lag1_max_q4_\", \"lag1_max_d_q3q4_\",\n",
    "\t\t\t\t \"lag1_min_q3_\", \"lag1_min_q4_\", \"lag1_min_d_q3q4_\"]\n",
    "\t\t\n",
    "\t\t# Remove redundancies\n",
    "\t\tfor i in range(len(to_rm)):\n",
    "\t\t\tfor j in range(ry.shape[1]):\n",
    "\t\t\t\trm_str = to_rm[i] + str(j)\n",
    "\t\t\t\tidx = feat_names.index(rm_str)\n",
    "\t\t\t\tfeat_names.pop(idx)\n",
    "\t\t\t\tret = np.delete(ret, idx, axis = 1)\n",
    "\n",
    "\t# Return\n",
    "\treturn ret, feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a959f51d-5d61-48d0-8fda-1ba8d8c9c981",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\MY Laptop\\\\Emotion Detection\\\\arduino'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 90\u001b[0m\n\u001b[0;32m     87\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMY Laptop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEmotion Detection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[0;32m     88\u001b[0m cols_to_ignore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \n\u001b[1;32m---> 90\u001b[0m gen_training_matrix(directory_path, output_file, cols_to_ignore)\n",
      "Cell \u001b[1;32mIn[3], line 29\u001b[0m, in \u001b[0;36mgen_training_matrix\u001b[1;34m(directory_path, output_file, cols_to_ignore)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Initialise return matrix\u001b[39;00m\n\u001b[0;32m     27\u001b[0m FINAL_MATRIX \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(directory_path):\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Ignore non-CSV files\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\MY Laptop\\\\Emotion Detection\\\\arduino'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "# from EEG_feature_extraction import generate_feature_vectors_from_samples\n",
    "\n",
    "\n",
    "def gen_training_matrix(directory_path, output_file, cols_to_ignore):\n",
    "    \"\"\"\n",
    "    Reads the csv files in directory_path and assembles the training matrix with \n",
    "    the features extracted using the functions from EEG_feature_extraction.\n",
    "    \n",
    "    Parameters:\n",
    "        directory_path (str): directory containing the CSV files to process.\n",
    "        output_file (str): filename for the output file.\n",
    "        cols_to_ignore (list): list of columns to ignore from the CSV\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 2D matrix containing the data read from the CSV\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialise return matrix\n",
    "    FINAL_MATRIX = None\n",
    "    \n",
    "    for x in os.listdir(directory_path):\n",
    "\n",
    "        # Ignore non-CSV files\n",
    "        if not x.lower().endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        # For safety we'll ignore files containing the substring \"test\". \n",
    "        # [Test files should not be in the dataset directory in the first place]\n",
    "        if 'test' in x.lower():\n",
    "            continue\n",
    "        try:\n",
    "            name, state, _ = x[:-4].split('-')\n",
    "        except:\n",
    "            print('Wrong file name', x)\n",
    "            sys.exit(-1)\n",
    "        if state.lower() == 'positive':\n",
    "            state = 2.\n",
    "        elif state.lower() == 'neutral':\n",
    "            state = 1.\n",
    "        elif state.lower() == 'negative':\n",
    "            state = 0.\n",
    "        else:\n",
    "            print('Wrong file name', x)\n",
    "            sys.exit(-1)\n",
    "            \n",
    "        print('Using file', x)\n",
    "        full_file_path = directory_path + '/' + x\n",
    "        vectors, header = generate_feature_vectors_from_samples(file_path=full_file_path, \n",
    "                                                                nsamples=150, \n",
    "                                                                period=1.,\n",
    "                                                                state=state,\n",
    "                                                                remove_redundant=True,\n",
    "                                                                cols_to_ignore=cols_to_ignore)\n",
    "        \n",
    "        print('Resulting vector shape for the file', vectors.shape)\n",
    "        \n",
    "        if FINAL_MATRIX is None:\n",
    "            FINAL_MATRIX = vectors\n",
    "        else:\n",
    "            FINAL_MATRIX = np.vstack([FINAL_MATRIX, vectors])\n",
    "\n",
    "    print('FINAL_MATRIX', FINAL_MATRIX.shape)\n",
    "    \n",
    "    # Shuffle rows\n",
    "    np.random.shuffle(FINAL_MATRIX)\n",
    "    \n",
    "    # Save to file\n",
    "    np.savetxt(output_file, FINAL_MATRIX, delimiter=',',\n",
    "               header=','.join(header), \n",
    "               comments='')\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # Hardcoded parameters\n",
    "    directory_path = r\"C:\\MY Laptop\\Emotion Detection\\arduino\" \n",
    "    output_file = r\"C:\\MY Laptop\\Emotion Detection\\data.csv\"  \n",
    "    cols_to_ignore = None \n",
    "\n",
    "    gen_training_matrix(directory_path, output_file, cols_to_ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fa4e0a-1732-451e-9b2f-923aba299de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
